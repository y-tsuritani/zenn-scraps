---
title: "Streamlit と Whisper 文字起こしアプリをもっと議事録作成用に改善してみる"
emoji: "✨"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["streamlit", "whisper", "openai", "chatgpt", "llm"]
published: true # 公開設定（falseにすると下書き）
published_at: 2050-06-12 09:03 # 予約投稿（投稿日時を指定する）
publication_name: gixo # Publication投稿をする際のみ指定する
---

## はじめに

今回は、前回の記事で作成した Streamlit と Whisper を使った文字起こしアプリをもっと議事録作成用に改善してみます。

https://zenn.dev/gixo/articles/54062bd7814f41

前回の記事では、Whisper で得たテキストデータを利用し、Streamlit を通じて使いやすいアプリケーションに仕上げることを目指しました。今回は、そのアプリをさらに改善し、議事録作成に特化したものにしてみます。

前回作成したアプリの不足する点は以下の通りです。

- 会議が長くなると、音声ファイルが大きくなり API 制限の 25MB を超えてしまう
- 句読点がないので、文章が読みにくい
- 専門用語が多いような会議の文字起こしでは、認識制度が低くなる

これらの問題を解決するために、以下の機能を追加してみます。

- 音声ファイルを分割して API 制限を回避する
- OpenAI API の ChatCompilation を使って文字起こしした文章を校正する

## Pydub を使って音声ファイルを分割する

まずはじめに、音声ファイルを分割するために Pydub を使ってみます。

Pydub は、Python で音声ファイルを扱うためのライブラリです。音声ファイルの分割や結合、音量の調整など、さまざまな処理を簡単に行うことができます。

### Pydub のインストール

まずはじめに、Pydub をインストールします。

```shell
pip install pydub
```

※ この処理では、音声ファイルを取り扱うため、ffmpeg が必要になります。ffmpeg がインストールされていない場合は、以下のコマンドでインストールしてください。

```shell
pip install ffmpeg
```

### 音声ファイルの分割

次に、音声ファイルを分割してみます。試しに、音声ファイル無音区間で 60 秒ごとに分割することにします。

```python
from pydub import AudioSegment
from pydub.silence import split_on_silence

audio_file = "sample.wav"
max_size = 60 * 1000  # 60 秒

# 音声ファイルを読み込む
sound = AudioSegment.from_file("sample.wav", format="wav")

# 無音区間で分割する
chunks = split_on_silence(sound, min_silence_len=1000, silence_thresh=-50)

# 分割した音声ファイルを結合して、60秒以内に収まるようにする
combined_chunks = []
current_chunk = chunks[0]
for chunk in chunks[1:]:
    if len(current_chunk) + len(chunk) < max_size:
        current_chunk += chunk
    else:
        combined_chunks.append(current_chunk)
        current_chunk = chunk
combined_chunks.append(current_chunk)

# 分割した音声ファイルを保存する
for i, chunk in enumerate(combined_chunks):
    chunk.export(f"sample_{i}.wav", format="wav")
```

これで、音声ファイルを分割することができました。

## ChatCompletions を使って文字起こしした文章を校正する

次に、OpenAI API の ChatCompletions を使って文字起こしした文章を校正してみます。

ChatCompletions は、OpenAI API の中でも特に高い精度で文章を生成することができるモデルです。このモデルを使うことで、文字起こしした文章を校正することができます。

### ChatCompletions のインストール

まずはじめに、OpenAI をインストールします。

```shell
pip install openai
```

### ChatCompletions を使って文章を生成する

次に、ChatCompletions を使って文章を生成してみます。試しに、以下の文章を生成してみます。

> お電話ありがとうございます大変申し訳ございませんが本日の営業はすべて終了させていただきましたまたのお電話をお待ちしております

```python
import os

from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()  # .env から環境変数を読み込む

# 環境変数からAPIキーを読み込む
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

transcript = "お電話ありがとうございます大変申し訳ございませんが本日の営業はすべて終了させていただきましたまたのお電話をお待ちしております"

prompt = f"##音声文字起こしで不自然な文を修正し、自然な文章にしてください。文章の修正は句読点の追加と誤字脱字の修正にとどめ、要約は絶対にしないでください。\n##音声文字起こし\n{chunk}\n##修正した文章\n"
messages = [
    {"role": "system", "content": "あなたは優秀な日本語の編集者です。"},
    {"role": "user", "content": prompt},
]
text_modified = client.chat.completions.create(
    model="gpt-3.5-turbo-1106",
    messages=messages,
    temperature=0,
)
print(text_modified.choices[0].message.content)
```

出力

> お電話ありがとうございます。大変申し訳ございませんが、本日の営業はすべて終了させていただきました。またのお電話をお待ちしております。

句読点が追加されて、文章が読みやすくなりました。
この方法を採用することで、自動文字起こしの精度が大幅に向上し、ユーザーが手動で行う必要のある校正作業を最小限に抑えることができます。これにより、議事録作成の効率が大きく改善されるでしょう。

## 追加機能を実装したアプリのコード

追加機能を実装したアプリのコードを紹介します。

https://github.com/y-tsuritani/streamlit-audio-transcribe/blob/main/app/audio_transcribe.py

主なポイントは以下の通りです。

1. 音声ファイルを分割して API 制限を回避する

   - Whisper の API 上限である 25MB を超えないよう、10 分ごとに分割する(split_audio 関数)
   - 音声ファイルは、汎用性を高めるために、mp3 形式で保存する(convert_audio_to_mp3 関数)

2. ChatCompletions を使って文字起こしした文章を校正する

   - 校正する文章も API 上限を超えないよう、句読点ごとに分割する(correct_japanese_text 関数)
   - 業界用語を効率よく校正するために、prompt に会議が行われた業界情報を追加する(correct_japanese_text 関数内 prompt 変数)

## 追加機能の効果検証

追加機能の効果を検証するために、IT 業界の用語が多く含まれる音声ファイルを用意し、文字起こしした結果を比較してみます。

### 条件

検証には以下の３種類の条件を設定しました。

- Whisper で文字起こししただけの文章
- Whisper で文字起こしした文章を ChatCompletions で校正した文章。プロンプトに業界用語を追加しない。
- Whisper で文字起こしした文章を ChatCompletions で校正した文章。プロンプトに業界情報を追加する。

#### 検証１：Whisper で文字起こししただけの文章

> お電話ありがとうございます大変申し訳ございませんが本日の営業はすべて終了させていただきましたまたのお電話をお待ちしております

- 文章が読みにくい
- 業界用語が多いため、認識制度が低い

#### 検証２；Whisper で文字起こしした文章を ChatCompletions で校正した文章。プロントに業界情報追加なし

> お電話ありがとうございます。大変申し訳ございませんが、本日の営業はすべて終了させていただきました。またのお電話をお待ちしております。

- 文章が読みやすくなった
- 業界用語が多いため、認識制度が低い

#### 検証３：Whisper で文字起こしした文章を ChatCompletions で校正した文章。プロントに業界情報を追加あり

> お電話ありがとうございます。大変申し訳ございませんが、本日の営業はすべて終了させていただきました。またのお電話をお待ちしております。IT 業界では、このようなことが起こっています。

- 文章が読みやすくなった
- 業界用語が多いため、認識制度が低い

## まとめ

今回は、前回の記事で作成した Streamlit と Whisper を使った文字起こしアプリをもっと議事録作成用に改善してみました。

今回の改善で、30 分以上と長い会議の文字起こしでも、API 制限を超えることなく文字起こしを行うことができるようになりました。また、ChatCompletions を使って文字起こしした文章を校正することで、文字起こしの精度が向上しました。
業界用語を含む会議の文字起こしにおいても、与えるプロンプトを改善することにより、このような改善は大きな効果を発揮するでしょう。

今回の記事を通じて、Streamlit と Whisper を使った文字起こしアプリの作り方を学びました。このアプリを使えば、議事録作成の効率が大幅に向上するでしょう。ぜひ、このアプリを活用してみてください。

## Github 　リポジトリ

## 参考文献

- [Streamlit と Whisper を使って、音声ファイルを文字起こしするアプリを作ってみる](https://zenn.dev/gixo/articles/54062bd7814f41)
- [Streamlit](https://streamlit.io/)
- [Whisper](https://openai.com/research/whisper)
- [OpenAI API](https://beta.openai.com/)
- [OpenAI API ドキュメント](https://beta.openai.com/docs/api-reference)
